<!DOCTYPE html>
<html>
    <head>
        <title>Leo | Operating System</title>
        <link rel="stylesheet" href="oscss.css">
        <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
            }
        });
    </script>  
    </head>
    <body>
        <h1 id="top">Operating System</h1>
        <h3> Table of contents</h3>
        <a id="gh" href="../index.html" style="position: fixed; right: 20px; top: 20px;">Go Home</a>
        <h4><a href="#Thread">Thread</a></h4>
        <h4><a href="#Concurrent Program Execution">Concurrent Program Execution</a></h4>
        <h4><a href="#Timesharing and Content Switches">Timesharing and Content Swiches</a></h4>
        <h4><a href="#Thread States">Thread States</a></h4>
        <h4><a href="#Interrupt">Interrupt</a></h4>
        <h4><a href="#preemptive scheduling">Preemptive Scheduling</a></h4>
        <h4><a href="#synchronization">Synchronization</a></h4>
        <h4><a href="#CS">Critical Section</a></h4>
        <h4><a href="#rc">Race Condition</a></h4>
        <h4><a href="#lock">Lock</a></h4>
        <h4><a href="#tb">Thread Blocking</a></h4>
        <h4><a href="#sem">Semaphores</a></h4>
        <h4><a href="#cv">Condition Variables</a></h4>
        <h4><a href="#dd">Deadlock</a></h4>

        <h2 id="Thread">Thread</h2>
        <ul>
            <li><strong>What is a thread?</strong>
                <ul>
                    <li>Thread is a sequence of instructions.</li>
                    <li>A normal sequential program consists of a single thread of execution</li>
                    <li>Threads provide a way for programmers to express concurrency
                        (i.e. multiple programs or sequences of instructions running, or 
                        appearing to run at the same time) in a program</li>
                    <li>There are multiple threads of execution
                        <ul>
                            <li>Threads may perform the same task.</li>
                            <li>Threads may perform different tasks.</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Properties of Thread:</strong>
                <ul>
                    <li>Resource Utilization: blocked/waiting threads give up resource</li>
                    <li>Parallelism: multiple threads exectuing simultaneously</li>
                    <li>Responsiveness: dedicate threads to</li>
                    <li>Priority: higher priority, more CPU time; lower priority, less CPU time</li>
                    <li>Modularization: organization of execution tasks</li>
                </ul>
            </li>
            <li><strong>Important Notes for Thread:</strong>
                <ul>
                    <li>A thread can create new threads using thread_fork</li>
                    <li>All threads share the program global variables and heap, but they have
                        private stack
                    </li>
                    <li>Operating system control which thread to run, orignal thread and the new 
                        thread runs concurrenctly.
                    </li>
                    <li>Once the threads start running, you cannot predict the behavior since you have 
                        no control.
                    </li>
                </ul>
            </li>
        </ul>
        <h2 id="Concurrent Program Execution">Concurrent Program Execution</h2>
        <ul>
            <li>One program has at least one thread and all threads share that program address space.</li>
            <li>Operating system job to prevent stacks overlapping each other --> but also make sure
                to get the maximum stack
            </li>
            <li><strong>multithread program gives:</strong>
                 <ul>
                     <li>the illusion that be able to runs multi-things at the same time</li>
                     <li>better organization of the program</li>
                     <li>better performance of the program</li>
                 </ul>
                </li>
            <li><strong>Implementation Concurrent Thread</strong>
                <ul>
                    <li>Hardware support: P(processors)C(cores)M(multithreading per core)
                        PCM threads can execute simultaneously.
                    </li>
                    <li>Timesharing: Multiple threads take turns on the same hardware(share CPU); rapidly switching 
                        between threads so all make progress; they are all making progress, use CPU one by one
                    </li>
                    <li>Hardware support + Timesharing: PCM + timesharing</li>
                </ul>
            </li>
        </ul>
        <h2 id="Timesharing and Content Switches">Timesharing and Content Switches</h2>
            <ul>
                <li>When timesharing, the switch from one thread to another is called a content switch</li>
                <li><strong>During the timesharing:</strong>
                    <ul>
                        <li>decide which thread will run next (go to operating system schedulor)</li>
                        <li>save the states(register value) of the current thread</li>
                        <li>load the states(register value) of the nwe thread</li>
                        <strong><li style="color:red">make sure that the thread that running CPU again at the exact position
                            and exact states when it pick up
                        </li>
                        </strong>
                        <li>Thread context must be saved/restored carefully</li>
                        <li>switchframe_switch (callee): save all the callee-save registers</li>
                        <li>thread_switch (caller): save all the caller-save registers</li>
                    </ul>
                </li>
            <li><strong>What causes context switch?</strong>
                <ul>
                    <li>thread_yield: running thread voluntarily allows other threads to run; give up CPU voluntarily</li>
                </ul>
            </li>
            <li><strong>Four ways of context-switch:</strong>
                <ul>
                    <li>Go to Blocked state --> wait something</li>
                    <li>Preemption: involuntarily give up the CPU since the scheduling quantum count down expires --> interrupts --> context switch</li>
                    <li>Thread_yield: voluntarily called thread yield</li>
                    <li>Thread terminated;</li>
                </ul>
            </li>
            </ul>
        <h2 id="Thread States">Thread States</h2>
        <ul>
            <li><strong>Thread states (3 states)</strong>
                <ul>
                    <li>running: thread is executing on the CPU right now; if CPU only support one thread
                        at a time, then only one thread has that state.
                    </li>
                    <li>ready: the thread is not waiting for anything except CPU; waiting to run instructions</li>
                    <li>blocked: any threads that is waiting for something that can continue. waiting to receive the "order"
                        to execute 
                    </li>
                    <li>transection:
                        <ul>
                            <li>ready to running: called by contextswitch</li>
                            <li>running to ready: called by yield</li>
                            <li>running to blocked: need something so that need to go to blocked to wait for that</li>
                            <li>blocked to ready: when something becomes available, then some threads will take the blocked thread
                                and push to ready state
                            </li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li><strong>Thread Stack after Coluntary Context Switch</strong>
                <ul>
                    <li>program calls thread_yield first to yield CPU</li>
                    <li>thread_yield then calls thread_switch, to perform a context switch</li>
                    <li>thread_switch chooses a new thread, calls switchframe_switch to perfrom low-level content switch</li>
                </ul>
            </li>
            <li><strong>Timesharing and Preemption:</strong>
                <ul>
                    <li>timesharing -- scheduling quantum (the upper bound on how long a thread can run before
                        must yield the CPU), it is involunteering stop.
                    </li>
                    <li>preemption forces a running thread to stop</li>
                    <li>Since CPU can only run one thread and that one is not aware that it needs to stop; the only way to stop a thread is through hardware -- using Interrupt!</li>
                </ul>
            </li>
        </ul>
        <h2 id="Interrupt">Interrupt</h2> <a href=""></a>
        <ul>
            <li>an interrupt is an event that occurs during the execution of a program</li>
            <li>interrupts are caused by system devices</li>
            <li>CPU know who causes the interrupt and OS handle the interrupts</li>
            <li>CPU has a trap table where stores some addresses of some codes.
                <ul>
                    <li>CPU --> receive interrupts --> stop executing user's program --> execute the code 
                        stored in address of the trap table (Interrupt handler (operating system code))
                    </li>
                </ul>
            </li>
            <li><strong>Interrupt handler</strong>
                <ol>
                    <li>create a trap frame; save every register in the system</li>
                    <li>called the actual handler --> perform device-specific processing</li>
                    <li>restores the saved thread context from the trap frame and resuems execution of the thread</li>
                </ol>
            </li>
            <li>Trap frame is always followed by the interrupt</li>
            <li>Interrupt handler stack frame followed by the trap frame</li>
            <li><strong>Difference between trap frame and switch functions</strong>
                <ul>
                    <li>trap frame saves all the registers comes before (the previous running program's registers)</li>
                    <li>thread_switch save all the registers between trap frame and itself (i.e. callee-save registers)</li>
                    <li>switchframe save all the registers (i.e. caller-save registers)</li>
                    <li>trap frame called by CPU not program(cannot be predict when to be called, so we need to save every register), 
                        while switch functions called by program!</li>
                </ul>
            </li>
        </ul>
        <h2 id="preemptive scheduling">Preemptive Scheduling</h2>
        <ul>
            <li>Preemptive Scheduling uses the schduling quantum</li>
            <li>Quantum cannot be too long --> not effective timesharing; cannot be too short --> spend more time on timesharing, not do so much work!</li>
            <li>Every time the new thread get a fresh quantum, so quantum does not carry over</li>
            <li>Every computer has clock --> run the count down --> when the count down is expire --> clock fire a interrupt --> causes CPU to execute the 
                interrupt handler so OS take control of the interrupts (i.e. execute content switch (yield -> thread_switch -> switchframe)
            <li><strong>Two passes to implement</strong>
                <ol>
                    <li>Every time there is a content switch, tell the clock to start a new count down --> really slow</li>
                    <li>Clock count down in a short period and repeat, when there is a time interrupt, go check (when the thread start running (record it))
                        whether it exceed its quantum, if yes, kick out, otherwise keep running.
                    </li>
                </ol>
            </li>
            </li>
        </ul>
        <h2 id="synchronization">Synchronization</h2>
        <ul>
            <li>
                All threads in a concurrent program <strong style="color:red">share access</strong> to the program's global variables and the heap (read & write).
            </li>
            <li>Any block of codes in a concurrent program where we have multiple threads reading and writing the shared variable(either global or heap) 
                is called <strong style="color: red">critical section</strong>
            </li>
        </ul>
        <h2 id="CS">Critical Section</h2>
            <ul>
                <li>The order of the instructions to be exectued in that section <strong style="color: red">matters</strong></li>
                <li>no control during preemption, no control over which thread run next --> OS have ability controlling</li>
                <li>Context switch happens expected to assembling, instead of C code.</li>
                <li>There are multiple programs running background, therefore, interrupts happens every time.</li>
            </ul>
        </ul>
        <h2 id="rc">Race Condition</h2>
        <ul>
            <li>when the program result depends on the order of execution.</li>
            <li>can cause: incorrect output, return error; memory error</li>
            <li>Race conditions occurs when multiple threads are reading and writing the same memory at the same time</li>
            <li>Source of race conditions:
                <ul>
                    <li>implementation</li>
                    <li>compiler</li>
                    <li>CPU</li>
                </ul>
            </li>
            <li>compiler and CPU introduce the race conditions due to optimization -- rearranging the code</li>
            <li>By applying memory model, CPU and complier knows which optimization is safe/unsafe</li>
            <li>In C99, volatile disable the optimization of CPU
                <ul>
                    <li>register allocation optimization: it keeps the up-to-date value in a register for as long as possible can</li>
                    <li>func a, func b, might use different register for register allocation --> do not know which one has the up-to-date value</li>
                    <li>volatile --> turn register optimization off; it forces to load from memory for every use</li>
                </ul>
            </li>
            <li>Identify race conditions
                <ul>
                    <li>inspect each variable; is it possible for multiple threads to read/write it at the same time?</li>
                    <li>constants and memoery that all threads only <strong style="color:red">read</strong>
                </ul>
            </li>
        </ul>
        <h2 id="lock">Enforcing Mutual Exclusion With Lock</h2>
        <ul>
            <li>Acquire/release must ensure that only one thread at a time can hold the lock, even if both attempt to Acquire at the same time.</li>
            <li>If a thread cannot Acquire the lock immediately, it must wait until the lock is available.</li>
            <li>Must <strong style="color: red">ACQUIRE</strong> the lock before exeucting the shared variable.</li>
            <li>C code cannot stop the interrupts & context switch, we need hardware to help 
                <ul>
                    <li>provide a way to implement <strong style="color: red">atomic test-and-set</strong> (i.e. atomic means cannot be interrupted!) for synchoronization primitives like locks</li>
                </ul>
            </li>
            <li>Mips & Arm use pair of value to implement Test-and-Set, they use the pair of values to check only.
                <ul>
                    <li>load-link: ll get the lock immediately;</li>
                    <li>store conditionally: sc get the value of the current lock;</li>
                    <li>return success if both value are the same; fail otherwise
                        <ul>
                            <li>if success: return tmp (which is the old value (immediate value of lock))
                                <ul>
                                    <li>if tmp is false, then we get the lock</li>
                                    <li>if tmp is true, then we keep spinning</li>
                                </ul>
                            </li>
                            <li>
                                if fail: return true, then we keep spinning
                            </li>
                        </ul>
                    </li>

                </ul>
            </li>
            <li>Spinlock and lock
                <ul>
                    <li>They both have a owener!
                        <ul>
                            <li>spinlock is owned by CPU</li>
                            <li>lock is owned by thread</li>
                        </ul>
                    </li>
                    <li>Spinlock <strong style="color:red">disable</strong> the interrupts
                        <ul>
                            <li>minimize the spinning</li>
                            <li>preemption is disable on the CPU --> because they are doing busy wait --> take up CPU</li>
                            <li><strong style="color:red">DO NOT</strong> use spin lock to protect large critical sections</li>
                        </ul>
                    </li>
                    <li>Some CPU can queue some interrupts during the spinlock is on</li>
                </ul>
            </li>
        </ul>
        <h2 id="tb">Thread Blocking</h2>
        <ul>
            <li>When a thread blocks, it stops running:
            <ul>
                <li>The scheduler chooses a new thread to run</li>
                <li>A context switch from the blocking thread to a new thread occurs</li>
                <li>The blocking thread is queued in a <strong style="color:red">Wait Queue</strong></li>
            </ul>
            </li>
            <li>Eventually, a blocked thread is signaled and awakened by another thread.</li>
        </ul>
        <h2 id="sem">Semaphores</h2>
        <ul>
            <li>Keep tracking the number of resources that are available. Try to synchoronizate in terms of number of resources</li>
            <li><strong style="color:red">Ownership!</strong> lock care about, but semaphores does not</li>
            <li>Can release it without own it</li>
            <li>Having a counter to keep track, the counter is non-negative.
                <ul>
                    <li>If the counter is zero, we go to sleep and wait for the counter to be anything else</li>
                    <li>If the counter is greater than zero, we take the resourse and decrement the counter</li>
                    <li>P(take the resourse, space++, item--) vs V(return the resourse, space--, item++)</li>
                    <li>No way to check the value of the counter in C, the only thing to do is P & V</li>
                </ul>
            </li>
            <li><strong>Type of Semaphores:</strong>
                <ul>
                    <li><strong>Binary Semaphore:</strong>
                        <ul>
                            <li>Similar to the lock, create with one initial resouce, when P it, take one resouce, V it, return one resource.</li>
                            <li>Do P first, then V. --> offer mutual exclusion</li>
                            <li>Initial resource and Maxmimun resource are 1</li>
                        </ul>
                    </li>
                    <li><strong>Counting semaphore:</strong>
                        <ul>
                            <li>A semaphore with an arbitrary number of resouces, no maximum resources</li>
                            <li>Do not care about the order of P and V</li>
                        </ul>
                    </li>
                    <li><strong>Barrier semaphore:</strong>
                        <ul>
                            <li>Use semaphore to force one thread wait another thread to finish.</li>
                            <li>Start the semaphore with zero resouces;</li> 
                            <li>Threads need to wait for the other thread needs to P sempahore once, for the threads are waiting on has to V the semaphore to access</li>
                        </ul>
                    </li>
                </ul>
            </li>
            <li>Proceducer/Consumer Synchronization
                <p>struct semaphore* Item, Space</p>
                <p>Item = sem_create("Buffer Item", 0);</p>
                <p>Space = sem_create("Buffer Spaces", N)</p>
                <br>
                <p>Producer's Pseudo-code:</p>
                <p>P(Spaces)</p>
                <p>add item to the buffer</p>
                <p>V(Items)</p>
                <br>
                <p>Consumer's Pseudo-code:</p>
                <p>P(Items)</p>
                <p>remove item from the buffer</p>
                <p>V(spaces)</p>
            </li>
        </ul>
        <h2 id="cv">Condition Variables</h2>
            <ul>
                <li>The safe to simultaneously fall asleep and give up the lock, so other threads can change the condition, then wake up by someone and own the lock</li>
                <li>wait: give up the lock --> go to sleep --> acquire the lock</li>
                <li><strong>Difference:</strong>
                    <ul>
                        <li>lock: mutual exclusion</li>
                        <li>sempahore: resources</li>
                        <li>CV: conditions </li>
                    </ul>
                </li>
            </ul>
        <h2 id="dd">Deadlocks</h2>
        <li>It forever stopped and never execute or make any progress</li>
        <li>Program stops running</li>
        <li>OS cannot detect the deadlock; since it cannot differentiate the deadlock or waiting for something</li>
        <li><strong>Solutions:</strong>
            <ul>
                <li>No Hold and Wait: prevent a thread from requesting resource while owning a resource (no wait, includes sleep and busy wait)</li>
                <li>Resource Ordering: Order the resource types and require that each thread acquire resources in increasing resource type order. (acquire in increasing order)</li>
            </ul>
        </li>
        <a href="#top" style="position:fixed; right: 20px; top: 50px">Back To Top</a>
    </body>
</html>